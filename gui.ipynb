{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27997b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "import PIL.Image\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from itertools import count\n",
    "import string\n",
    "from tkinter import *\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import Tkinter as tk\n",
    "except:\n",
    "    import tkinter as tk\n",
    "\n",
    "image_x, image_y = 64, 64\n",
    "from keras.models import load_model\n",
    "\n",
    "# classifier = load_model('asl_detection.h5')\n",
    "\n",
    "def give_char():\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    test_image = image.load_img('tmp1.png', target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    chars = \"ABCDEFGHIJKMNOPQRSTUVWXYZ\"\n",
    "    indx = np.argmax(result[0])\n",
    "    print(indx)\n",
    "    return (chars[indx])\n",
    "\n",
    "\n",
    "def check_sim(i, file_map):\n",
    "    for item in file_map:\n",
    "        for word in file_map[item]:\n",
    "            if (i == word):\n",
    "                return 1, item\n",
    "    return -1, \"\"\n",
    "\n",
    "\n",
    "op_dest = r\"C:\\Users\\Pilli Akshitha\\OneDrive\\Desktop\\AD Sign language\\AD Sign language\\filtered_data\\\\\"\n",
    "alpha_dest = r\"C:\\Users\\Pilli Akshitha\\OneDrive\\Desktop\\AD Sign language\\AD Sign language\\alphabet\\\\\"\n",
    "dirListing = os.listdir(op_dest)\n",
    "editFiles = []\n",
    "for item in dirListing:\n",
    "    if \".webp\" in item:\n",
    "        editFiles.append(item)\n",
    "\n",
    "file_map = {}\n",
    "for i in editFiles:\n",
    "    tmp = i.replace(\".webp\", \"\")\n",
    "    tmp = tmp.split()\n",
    "    file_map[i] = tmp\n",
    "\n",
    "\n",
    "def func(a):\n",
    "    all_frames = []\n",
    "    final = PIL.Image.new('RGB', (380, 260))\n",
    "    words = a.split()\n",
    "    for i in words:\n",
    "        flag, sim = check_sim(i, file_map)\n",
    "        if (flag == -1):\n",
    "            for j in i:\n",
    "                print(j)\n",
    "                speak_output(j)\n",
    "                im = PIL.Image.open(alpha_dest + str(j).lower() + \"_small.gif\")\n",
    "                frameCnt = im.n_frames\n",
    "                for frame_cnt in range(frameCnt):\n",
    "                    im.seek(frame_cnt)\n",
    "                    im.save(\"tmp.png\")\n",
    "                    img = cv2.imread(\"tmp.png\")\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (380, 260))\n",
    "                    im_arr = PIL.Image.fromarray(img)\n",
    "                    for itr in range(15):\n",
    "                        all_frames.append(im_arr)\n",
    "        else:\n",
    "            print(sim)\n",
    "            speak_output(sim)\n",
    "            im = PIL.Image.open(op_dest + sim)\n",
    "            im.info.pop('background', None)\n",
    "            im.save('tmp.gif', 'gif', save_all=True)\n",
    "            im = PIL.Image.open(\"tmp.gif\")\n",
    "            frameCnt = im.n_frames\n",
    "            for frame_cnt in range(frameCnt):\n",
    "                im.seek(frame_cnt)\n",
    "                im.save(\"tmp.png\")\n",
    "                img = cv2.imread(\"tmp.png\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (380, 260))\n",
    "                im_arr = PIL.Image.fromarray(img)\n",
    "                all_frames.append(im_arr)\n",
    "                all_frames.append(im_arr)  # Add an additional frame to add pause after each symbol\n",
    "    final.save(\"out.gif\", save_all=True, append_images=all_frames, duration=100, loop=0)\n",
    "    return all_frames\n",
    "\n",
    "\n",
    "def speak_output(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "img_counter = 0\n",
    "img_text = ''\n",
    "\n",
    "\n",
    "class Tk_Manage(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        container = tk.Frame(self)\n",
    "        container.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "        container.grid_rowconfigure(0, weight=1)\n",
    "        container.grid_columnconfigure(0, weight=1)\n",
    "        self.frames = {}\n",
    "        for F in (StartPage, VtoS):\n",
    "            frame = F(container, self)\n",
    "            self.frames[F] = frame\n",
    "            frame.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        self.show_frame(StartPage)\n",
    "\n",
    "    def show_frame(self, cont):\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "\n",
    "\n",
    "class StartPage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.config(bg='#FAE8E0')  # Set background color\n",
    "        label = tk.Label(self, text=\"Sign Language Translator\", font=(\"Verdana\", 12), bg='#FAE8E0')\n",
    "        label.pack(pady=10, padx=10)\n",
    "        button_text_to_sign = tk.Button(self, text=\"Text to Sign\", command=lambda: controller.show_frame(VtoS),\n",
    "                                         bg='#B6E2D3', fg='#145DA0', font=(\"Verdana\", 10))\n",
    "        # Increase button size by 40%\n",
    "        button_text_to_sign.config(height=int(button_text_to_sign['height'] * 1.4), width=int(button_text_to_sign['width'] * 1.4))\n",
    "        button_text_to_sign.pack()\n",
    "\n",
    "        # New button for camera detection\n",
    "        button_camera_detection = tk.Button(self, text=\"Camera Detection\", command=self.start_camera_detection,\n",
    "                                            bg='#B6E2D3', fg='#145DA0', font=(\"Verdana\", 10))\n",
    "        # Increase button size by 40%\n",
    "        button_camera_detection.config(height=int(button_camera_detection['height'] * 1.4),\n",
    "                                        width=int(button_camera_detection['width'] * 1.4))\n",
    "        button_camera_detection.pack()\n",
    "\n",
    "    def start_camera_detection(self):\n",
    "        # Execute the code from test.py for camera detection\n",
    "        exec(open(\"test.py\").read())\n",
    "\n",
    "\n",
    "# VtoS class\n",
    "class VtoS(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        cnt = 0\n",
    "        gif_frames = []\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.config(bg='#FAE8E0')  # Set background color\n",
    "        label = tk.Label(self, text=\"Text to Sign\", font=(\"Verdana\", 12), bg='#FAE8E0')\n",
    "        label.pack(pady=10, padx=10)\n",
    "        gif_box = tk.Label(self)\n",
    "\n",
    "        button1 = tk.Button(self, text=\"Back to Home\", command=lambda: controller.show_frame(StartPage),\n",
    "                            bg='#B6E2D3', fg='#145DA0', font=(\"Verdana\", 10))\n",
    "        # Increase button size by 40%\n",
    "        button1.config(height=int(button1['height'] * 1.4), width=int(button1['width'] * 1.4))\n",
    "        button1.pack()\n",
    "\n",
    "        def gif_stream():\n",
    "            global cnt\n",
    "            global gif_frames\n",
    "            if (cnt == len(gif_frames)):\n",
    "                return\n",
    "            img = gif_frames[cnt]\n",
    "            cnt += 1\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            gif_box.imgtk = imgtk\n",
    "            gif_box.configure(image=imgtk)\n",
    "            gif_box.after(50, gif_stream)\n",
    "\n",
    "        def hear_voice(inputtxt):\n",
    "            store = sr.Recognizer()\n",
    "            with sr.Microphone() as s:\n",
    "                audio_input = store.record(s, duration=10)\n",
    "                try:\n",
    "                    text_output = store.recognize_google(audio_input)\n",
    "                    inputtxt.insert(END, text_output)\n",
    "                    # Automatically convert to sign language after voice detection\n",
    "                    Take_input(inputtxt)\n",
    "                except:\n",
    "                    print(\"Error Hearing Voice\")\n",
    "                    inputtxt.insert(END, '')\n",
    "\n",
    "        def Take_input(inputtxt):\n",
    "            INPUT = inputtxt.get(\"1.0\", \"end-1c\")\n",
    "            print(INPUT)\n",
    "            global gif_frames\n",
    "            gif_frames = func(INPUT)\n",
    "            global cnt\n",
    "            cnt = 0\n",
    "            gif_stream()\n",
    "            gif_box.place(x=400, y=160)\n",
    "\n",
    "        l = tk.Label(self, text=\"Enter Text or Voice:\", bg='#FAE8E0')\n",
    "        l1 = tk.Label(self, text=\"OR\", bg='#FAE8E0')\n",
    "        inputtxt = tk.Text(self, height=4, width=25)\n",
    "        voice_button = tk.Button(self, height=2, width=20, text=\"Record Voice\", command=lambda: hear_voice(inputtxt),\n",
    "                                 bg='#B6E2D3', fg='#145DA0', font=(\"Verdana\", 10))\n",
    "        # Increase button size by 40%\n",
    "        voice_button.config(height=int(voice_button['height'] * 1.4), width=int(voice_button['width'] * 1.4))\n",
    "        voice_button.place(x=50, y=180)\n",
    "        Display = tk.Button(self, height=2, width=20, text=\"Convert\", command=lambda: Take_input(inputtxt),\n",
    "                            bg='#B6E2D3', fg='#145DA0', font=(\"Verdana\", 10))\n",
    "        # Increase button size by 40%\n",
    "        Display.config(height=int(Display['height'] * 1.4), width=int(Display['width'] * 1.4))\n",
    "        l.place(x=50, y=160)\n",
    "        l1.place(x=115, y=230)\n",
    "        inputtxt.place(x=50, y=250)\n",
    "        Display.pack()\n",
    "\n",
    "\n",
    "app = Tk_Manage()\n",
    "app.geometry(\"800x750\")\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "292bb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "import PIL.Image\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from itertools import count\n",
    "import string\n",
    "from tkinter import *\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import Tkinter as tk\n",
    "except:\n",
    "    import tkinter as tk\n",
    "\n",
    "image_x, image_y = 64, 64\n",
    "from keras.models import load_model\n",
    "\n",
    "# classifier = load_model('asl_detection.h5')\n",
    "\n",
    "def give_char():\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    test_image = image.load_img('tmp1.png', target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    chars = \"ABCDEFGHIJKMNOPQRSTUVWXYZ\"\n",
    "    indx = np.argmax(result[0])\n",
    "    print(indx)\n",
    "    return (chars[indx])\n",
    "\n",
    "\n",
    "def check_sim(i, file_map):\n",
    "    for item in file_map:\n",
    "        for word in file_map[item]:\n",
    "            if (i == word):\n",
    "                return 1, item\n",
    "    return -1, \"\"\n",
    "\n",
    "\n",
    "op_dest = r\"C:\\Users\\Pilli Akshitha\\OneDrive\\Desktop\\AD Sign language\\AD Sign language\\filtered_data\\\\\"\n",
    "alpha_dest = r\"C:\\Users\\Pilli Akshitha\\OneDrive\\Desktop\\AD Sign language\\AD Sign language\\alphabet\\\\\"\n",
    "dirListing = os.listdir(op_dest)\n",
    "editFiles = []\n",
    "for item in dirListing:\n",
    "    if \".webp\" in item:\n",
    "        editFiles.append(item)\n",
    "\n",
    "file_map = {}\n",
    "for i in editFiles:\n",
    "    tmp = i.replace(\".webp\", \"\")\n",
    "    tmp = tmp.split()\n",
    "    file_map[i] = tmp\n",
    "\n",
    "\n",
    "def func(a):\n",
    "    all_frames = []\n",
    "    final = PIL.Image.new('RGB', (380, 260))\n",
    "    words = a.split()\n",
    "    for i in words:\n",
    "        flag, sim = check_sim(i, file_map)\n",
    "        if (flag == -1):\n",
    "            for j in i:\n",
    "                print(j)\n",
    "                speak_output(j)\n",
    "                im = PIL.Image.open(alpha_dest + str(j).lower() + \"_small.gif\")\n",
    "                frameCnt = im.n_frames\n",
    "                for frame_cnt in range(frameCnt):\n",
    "                    im.seek(frame_cnt)\n",
    "                    im.save(\"tmp.png\")\n",
    "                    img = cv2.imread(\"tmp.png\")\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (380, 260))\n",
    "                    im_arr = PIL.Image.fromarray(img)\n",
    "                    for itr in range(15):\n",
    "                        all_frames.append(im_arr)\n",
    "        else:\n",
    "            print(sim)\n",
    "            speak_output(sim)\n",
    "            im = PIL.Image.open(op_dest + sim)\n",
    "            im.info.pop('background', None)\n",
    "            im.save('tmp.gif', 'gif', save_all=True)\n",
    "            im = PIL.Image.open(\"tmp.gif\")\n",
    "            frameCnt = im.n_frames\n",
    "            for frame_cnt in range(frameCnt):\n",
    "                im.seek(frame_cnt)\n",
    "                im.save(\"tmp.png\")\n",
    "                img = cv2.imread(\"tmp.png\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (380, 260))\n",
    "                im_arr = PIL.Image.fromarray(img)\n",
    "                all_frames.append(im_arr)\n",
    "                all_frames.append(im_arr)  # Add an additional frame to add pause after each symbol\n",
    "    final.save(\"out.gif\", save_all=True, append_images=all_frames, duration=100, loop=0)\n",
    "    return all_frames\n",
    "\n",
    "\n",
    "def speak_output(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "img_counter = 0\n",
    "img_text = ''\n",
    "\n",
    "\n",
    "class Tk_Manage(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        container = tk.Frame(self)\n",
    "        container.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "        container.grid_rowconfigure(0, weight=1)\n",
    "        container.grid_columnconfigure(0, weight=1)\n",
    "        self.frames = {}\n",
    "        for F in (StartPage, VtoS):\n",
    "            frame = F(container, self)\n",
    "            self.frames[F] = frame\n",
    "            frame.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        self.show_frame(StartPage)\n",
    "\n",
    "    def show_frame(self, cont):\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "\n",
    "\n",
    "class StartPage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.config(bg='#189AB4')  # Set background color\n",
    "        label = tk.Label(self, text=\"Sign Language Translator\", font=(\"Verdana\", 12), bg='#189AB4')\n",
    "        label.pack(pady=10, padx=10)\n",
    "        button_text_to_sign = tk.Button(self, text=\"Text to Sign\", command=lambda: controller.show_frame(VtoS),\n",
    "                                         bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        button_text_to_sign.pack()\n",
    "\n",
    "        # New button for camera detection\n",
    "        button_camera_detection = tk.Button(self, text=\"Camera Detection\", command=self.start_camera_detection,\n",
    "                                            bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        button_camera_detection.pack()\n",
    "\n",
    "    def start_camera_detection(self):\n",
    "        # Execute the code from test.py for camera detection\n",
    "        exec(open(\"test.py\").read())\n",
    "\n",
    "\n",
    "# VtoS class\n",
    "class VtoS(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        cnt = 0\n",
    "        gif_frames = []\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.config(bg='#189AB4')  # Set background color\n",
    "        label = tk.Label(self, text=\"Text to Sign\", font=(\"Verdana\", 12), bg='#189AB4')\n",
    "        label.pack(pady=10, padx=10)\n",
    "        gif_box = tk.Label(self)\n",
    "\n",
    "        button1 = tk.Button(self, text=\"Back to Home\", command=lambda: controller.show_frame(StartPage),\n",
    "                            bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        button1.pack()\n",
    "\n",
    "        def gif_stream():\n",
    "            global cnt\n",
    "            global gif_frames\n",
    "            if (cnt == len(gif_frames)):\n",
    "                return\n",
    "            img = gif_frames[cnt]\n",
    "            cnt += 1\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            gif_box.imgtk = imgtk\n",
    "            gif_box.configure(image=imgtk)\n",
    "            gif_box.after(50, gif_stream)\n",
    "\n",
    "        def hear_voice(inputtxt):\n",
    "            store = sr.Recognizer()\n",
    "            with sr.Microphone() as s:\n",
    "                audio_input = store.record(s, duration=10)\n",
    "                try:\n",
    "                    text_output = store.recognize_google(audio_input)\n",
    "                    inputtxt.insert(END, text_output)\n",
    "                    # Automatically convert to sign language after voice detection\n",
    "                    Take_input(inputtxt)\n",
    "                except:\n",
    "                    print(\"Error Hearing Voice\")\n",
    "                    inputtxt.insert(END, '')\n",
    "\n",
    "        def Take_input(inputtxt):\n",
    "            INPUT = inputtxt.get(\"1.0\", \"end-1c\")\n",
    "            print(INPUT)\n",
    "            global gif_frames\n",
    "            gif_frames = func(INPUT)\n",
    "            global cnt\n",
    "            cnt = 0\n",
    "            gif_stream()\n",
    "            gif_box.place(x=400, y=160)\n",
    "\n",
    "        l = tk.Label(self, text=\"Enter Text or Voice:\", bg='#189AB4')\n",
    "        l1 = tk.Label(self, text=\"OR\", bg='#189AB4')\n",
    "        inputtxt = tk.Text(self, height=4, width=25)\n",
    "        voice_button = tk.Button(self, height=2, width=20, text=\"Record Voice\", command=lambda: hear_voice(inputtxt),\n",
    "                                 bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        voice_button.place(x=50, y=180)\n",
    "        Display = tk.Button(self, height=2, width=20, text=\"Convert\", command=lambda: Take_input(inputtxt),\n",
    "                            bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        Display.place(x=50, y=250)\n",
    "        l.place(x=50, y=160)\n",
    "        l1.place(x=115, y=230)\n",
    "        inputtxt.place(x=50, y=250)\n",
    "        Display.pack()\n",
    "\n",
    "\n",
    "app = Tk_Manage()\n",
    "app.geometry(\"800x750\")\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575b1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "import PIL.Image\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from itertools import count\n",
    "import string\n",
    "from tkinter import *\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import Tkinter as tk\n",
    "except:\n",
    "    import tkinter as tk\n",
    "\n",
    "image_x, image_y = 64, 64\n",
    "from keras.models import load_model\n",
    "\n",
    "# classifier = load_model('asl_detection.h5')\n",
    "\n",
    "def give_char():\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    test_image = image.load_img('tmp1.png', target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    chars = \"ABCDEFGHIJKMNOPQRSTUVWXYZ\"\n",
    "    indx = np.argmax(result[0])\n",
    "    print(indx)\n",
    "    return (chars[indx])\n",
    "\n",
    "\n",
    "def check_sim(i, file_map):\n",
    "    for item in file_map:\n",
    "        for word in file_map[item]:\n",
    "            if (i == word):\n",
    "                return 1, item\n",
    "    return -1, \"\"\n",
    "\n",
    "\n",
    "op_dest = r\"C:\\Users\\Pilli Akshitha\\OneDrive\\Desktop\\AD Sign language\\AD Sign language\\filtered_data\\\\\"\n",
    "alpha_dest = r\"C:\\Users\\Pilli Akshitha\\OneDrive\\Desktop\\AD Sign language\\AD Sign language\\alphabet\\\\\"\n",
    "dirListing = os.listdir(op_dest)\n",
    "editFiles = []\n",
    "for item in dirListing:\n",
    "    if \".webp\" in item:\n",
    "        editFiles.append(item)\n",
    "\n",
    "file_map = {}\n",
    "for i in editFiles:\n",
    "    tmp = i.replace(\".webp\", \"\")\n",
    "    tmp = tmp.split()\n",
    "    file_map[i] = tmp\n",
    "\n",
    "\n",
    "def func(a):\n",
    "    all_frames = []\n",
    "    final = PIL.Image.new('RGB', (380, 260))\n",
    "    words = a.split()\n",
    "    for i in words:\n",
    "        flag, sim = check_sim(i, file_map)\n",
    "        if (flag == -1):\n",
    "            for j in i:\n",
    "                print(j)\n",
    "                speak_output(j)\n",
    "                im = PIL.Image.open(alpha_dest + str(j).lower() + \"_small.gif\")\n",
    "                frameCnt = im.n_frames\n",
    "                for frame_cnt in range(frameCnt):\n",
    "                    im.seek(frame_cnt)\n",
    "                    im.save(\"tmp.png\")\n",
    "                    img = cv2.imread(\"tmp.png\")\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (380, 260))\n",
    "                    im_arr = PIL.Image.fromarray(img)\n",
    "                    for itr in range(15):\n",
    "                        all_frames.append(im_arr)\n",
    "        else:\n",
    "            print(sim)\n",
    "            speak_output(sim)\n",
    "            im = PIL.Image.open(op_dest + sim)\n",
    "            im.info.pop('background', None)\n",
    "            im.save('tmp.gif', 'gif', save_all=True)\n",
    "            im = PIL.Image.open(\"tmp.gif\")\n",
    "            frameCnt = im.n_frames\n",
    "            for frame_cnt in range(frameCnt):\n",
    "                im.seek(frame_cnt)\n",
    "                im.save(\"tmp.png\")\n",
    "                img = cv2.imread(\"tmp.png\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (380, 260))\n",
    "                im_arr = PIL.Image.fromarray(img)\n",
    "                all_frames.append(im_arr)\n",
    "                all_frames.append(im_arr)  # Add an additional frame to add pause after each symbol\n",
    "    final.save(\"out.gif\", save_all=True, append_images=all_frames, duration=100, loop=0)\n",
    "    return all_frames\n",
    "\n",
    "\n",
    "def speak_output(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "img_counter = 0\n",
    "img_text = ''\n",
    "\n",
    "\n",
    "class Tk_Manage(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        container = tk.Frame(self)\n",
    "        container.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "        container.grid_rowconfigure(0, weight=1)\n",
    "        container.grid_columnconfigure(0, weight=1)\n",
    "        self.frames = {}\n",
    "        for F in (StartPage, VtoS):\n",
    "            frame = F(container, self)\n",
    "            self.frames[F] = frame\n",
    "            frame.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        self.show_frame(StartPage)\n",
    "\n",
    "    def show_frame(self, cont):\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "\n",
    "\n",
    "class StartPage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.config(bg='#189AB4')  # Set background color\n",
    "        label = tk.Label(self, text=\"Sign Language Translator\", font=(\"Verdana\", 12), bg='#189AB4')\n",
    "        label.pack(pady=10, padx=10)\n",
    "        button_text_to_sign = tk.Button(self, text=\"Text to Sign\", command=lambda: controller.show_frame(VtoS),\n",
    "                                         bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        button_text_to_sign.pack()\n",
    "\n",
    "        # New button for camera detection\n",
    "        button_camera_detection = tk.Button(self, text=\"Camera Detection\", command=self.start_camera_detection,\n",
    "                                            bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        button_camera_detection.pack()\n",
    "\n",
    "        # Load background image\n",
    "        self.background_image = PIL.Image.open(\"C:/Users/Pilli Akshitha/OneDrive/Desktop/AD Sign language/AD Sign language/a2.png\")\n",
    "        self.background_photo = ImageTk.PhotoImage(self.background_image)\n",
    "        self.background_label = tk.Label(self, image=self.background_photo)\n",
    "        self.background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "    def start_camera_detection(self):\n",
    "        # Execute the code from test.py for camera detection\n",
    "        exec(open(\"test.py\").read())\n",
    "\n",
    "\n",
    "# VtoS class\n",
    "class VtoS(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        cnt = 0\n",
    "        gif_frames = []\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        self.config(bg='#189AB4')  # Set background color\n",
    "        label = tk.Label(self, text=\"Text to Sign\", font=(\"Verdana\", 12), bg='#189AB4')\n",
    "        label.pack(pady=10, padx=10)\n",
    "        gif_box = tk.Label(self)\n",
    "\n",
    "        button1 = tk.Button(self, text=\"Back to Home\", command=lambda: controller.show_frame(StartPage),\n",
    "                            bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        button1.pack()\n",
    "\n",
    "        def gif_stream():\n",
    "            global cnt\n",
    "            global gif_frames\n",
    "            if (cnt == len(gif_frames)):\n",
    "                return\n",
    "            img = gif_frames[cnt]\n",
    "            cnt += 1\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            gif_box.imgtk = imgtk\n",
    "            gif_box.configure(image=imgtk)\n",
    "            gif_box.after(50, gif_stream)\n",
    "\n",
    "        def hear_voice(inputtxt):\n",
    "            store = sr.Recognizer()\n",
    "            with sr.Microphone() as s:\n",
    "                audio_input = store.record(s, duration=10)\n",
    "                try:\n",
    "                    text_output = store.recognize_google(audio_input)\n",
    "                    inputtxt.insert(END, text_output)\n",
    "                    # Automatically convert to sign language after voice detection\n",
    "                    Take_input(inputtxt)\n",
    "                except:\n",
    "                    print(\"Error Hearing Voice\")\n",
    "                    inputtxt.insert(END, '')\n",
    "\n",
    "        def Take_input(inputtxt):\n",
    "            INPUT = inputtxt.get(\"1.0\", \"end-1c\")\n",
    "            print(INPUT)\n",
    "            global gif_frames\n",
    "            gif_frames = func(INPUT)\n",
    "            global cnt\n",
    "            cnt = 0\n",
    "            gif_stream()\n",
    "            gif_box.place(x=400, y=160)\n",
    "\n",
    "        l = tk.Label(self, text=\"Enter Text or Voice:\", bg='#189AB4')\n",
    "        l1 = tk.Label(self, text=\"OR\", bg='#189AB4')\n",
    "        inputtxt = tk.Text(self, height=4, width=25)\n",
    "        voice_button = tk.Button(self, height=2, width=20, text=\"Record Voice\", command=lambda: hear_voice(inputtxt),\n",
    "                                 bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        voice_button.place(x=50, y=180)\n",
    "        Display = tk.Button(self, height=2, width=20, text=\"Convert\", command=lambda: Take_input(inputtxt),\n",
    "                            bg='#D4F1F4', fg='black', font=(\"Verdana\", 10))\n",
    "        # Do not increase button size\n",
    "        Display.place(x=50, y=250)\n",
    "        l.place(x=50, y=160)\n",
    "        l1.place(x=115, y=230)\n",
    "        inputtxt.place(x=50, y=250)\n",
    "        Display.pack()\n",
    "\n",
    "\n",
    "app = Tk_Manage()\n",
    "app.geometry(\"800x750\")\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d882b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pilli akshitha\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pilli akshitha\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement pyimage3 (from versions: none)\n",
      "ERROR: No matching distribution found for pyimage3\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pilli akshitha\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pilli akshitha\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\pilli akshitha\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pyimage3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4db8c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import PIL\n",
    "from PIL import ImageTk\n",
    "import PIL.Image\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from itertools import count\n",
    "import string\n",
    "from tkinter import *\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import Tkinter as tk\n",
    "except:\n",
    "    import tkinter as tk\n",
    "\n",
    "image_x, image_y = 64, 64\n",
    "from keras.models import load_model\n",
    "\n",
    "# classifier = load_model('asl_detection.h5')\n",
    "\n",
    "def give_char():\n",
    "    import numpy as np\n",
    "    from keras.preprocessing import image\n",
    "    test_image = image.load_img('tmp1.png', target_size=(64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    result = classifier.predict(test_image)\n",
    "    print(result)\n",
    "    chars = \"ABCDEFGHIJKMNOPQRSTUVWXYZ\"\n",
    "    indx = np.argmax(result[0])\n",
    "    print(indx)\n",
    "    return (chars[indx])\n",
    "\n",
    "\n",
    "def check_sim(i, file_map):\n",
    "    for item in file_map:\n",
    "        for word in file_map[item]:\n",
    "            if (i == word):\n",
    "                return 1, item\n",
    "    return -1, \"\"\n",
    "\n",
    "\n",
    "op_dest = r\"C:\\Users\\Pilli Akshitha\\OneDrive\\Desktop\\AD Sign language\\AD Sign language\\filtered_data\\\\\"\n",
    "alpha_dest = r\"C:\\Users\\Pilli Akshitha\\OneDrive\\Desktop\\AD Sign language\\AD Sign language\\alphabet\\\\\"\n",
    "dirListing = os.listdir(op_dest)\n",
    "editFiles = []\n",
    "for item in dirListing:\n",
    "    if \".webp\" in item:\n",
    "        editFiles.append(item)\n",
    "\n",
    "file_map = {}\n",
    "for i in editFiles:\n",
    "    tmp = i.replace(\".webp\", \"\")\n",
    "    tmp = tmp.split()\n",
    "    file_map[i] = tmp\n",
    "\n",
    "\n",
    "def func(a):\n",
    "    all_frames = []\n",
    "    final = PIL.Image.new('RGB', (380, 260))\n",
    "    words = a.split()\n",
    "    for i in words:\n",
    "        flag, sim = check_sim(i, file_map)\n",
    "        if (flag == -1):\n",
    "            for j in i:\n",
    "                print(j)\n",
    "                speak_output(j)\n",
    "                im = PIL.Image.open(alpha_dest + str(j).lower() + \"_small.gif\")\n",
    "                frameCnt = im.n_frames\n",
    "                for frame_cnt in range(frameCnt):\n",
    "                    im.seek(frame_cnt)\n",
    "                    im.save(\"tmp.png\")\n",
    "                    img = cv2.imread(\"tmp.png\")\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (380, 260))\n",
    "                    im_arr = PIL.Image.fromarray(img)\n",
    "                    for itr in range(15):\n",
    "                        all_frames.append(im_arr)\n",
    "        else:\n",
    "            print(sim)\n",
    "            speak_output(sim)\n",
    "            im = PIL.Image.open(op_dest + sim)\n",
    "            im.info.pop('background', None)\n",
    "            im.save('tmp.gif', 'gif', save_all=True)\n",
    "            im = PIL.Image.open(\"tmp.gif\")\n",
    "            frameCnt = im.n_frames\n",
    "            for frame_cnt in range(frameCnt):\n",
    "                im.seek(frame_cnt)\n",
    "                im.save(\"tmp.png\")\n",
    "                img = cv2.imread(\"tmp.png\")\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (380, 260))\n",
    "                im_arr = PIL.Image.fromarray(img)\n",
    "                all_frames.append(im_arr)\n",
    "                all_frames.append(im_arr)  # Add an additional frame to add pause after each symbol\n",
    "    final.save(\"out.gif\", save_all=True, append_images=all_frames, duration=100, loop=0)\n",
    "    return all_frames\n",
    "\n",
    "\n",
    "def speak_output(text):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "\n",
    "img_counter = 0\n",
    "img_text = ''\n",
    "\n",
    "\n",
    "class Tk_Manage(tk.Tk):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        tk.Tk.__init__(self, *args, **kwargs)\n",
    "        container = tk.Frame(self)\n",
    "        container.pack(side=\"top\", fill=\"both\", expand=True)\n",
    "        container.grid_rowconfigure(0, weight=1)\n",
    "        container.grid_columnconfigure(0, weight=1)\n",
    "        self.frames = {}\n",
    "        for F in (StartPage, VtoS):\n",
    "            frame = F(container, self)\n",
    "            self.frames[F] = frame\n",
    "            frame.grid(row=0, column=0, sticky=\"nsew\")\n",
    "        self.show_frame(StartPage)\n",
    "\n",
    "    def show_frame(self, cont):\n",
    "        frame = self.frames[cont]\n",
    "        frame.tkraise()\n",
    "\n",
    "\n",
    "class StartPage(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        # Load background image\n",
    "        self.background_image = PIL.Image.open(\"C:/Users/Pilli Akshitha/OneDrive/Desktop/AD Sign language/AD Sign language/a1.jpg\")\n",
    "        self.background_photo = ImageTk.PhotoImage(self.background_image)\n",
    "        self.background_label = tk.Label(self, image=self.background_photo)\n",
    "        self.background_label.place(x=0, y=0, relwidth=1, relheight=1)\n",
    "\n",
    "        label = tk.Label(self, text=\"Sign Language Translator\", font=(\"Verdana\", 12))\n",
    "        label.pack(pady=10, padx=10)\n",
    "        button_text_to_sign = tk.Button(self, text=\"Text to Sign\", command=lambda: controller.show_frame(VtoS), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        button_text_to_sign.pack()\n",
    "\n",
    "        # New button for camera detection\n",
    "        button_camera_detection = tk.Button(self, text=\"Camera Detection\", command=self.start_camera_detection, bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        button_camera_detection.pack()\n",
    "\n",
    "    def start_camera_detection(self):\n",
    "        # Execute the code from test.py for camera detection\n",
    "        exec(open(\"test.py\").read())\n",
    "\n",
    "\n",
    "# VtoS class\n",
    "class VtoS(tk.Frame):\n",
    "    def __init__(self, parent, controller):\n",
    "        cnt = 0\n",
    "        gif_frames = []\n",
    "        tk.Frame.__init__(self, parent)\n",
    "        label = tk.Label(self, text=\"Text to Sign\", font=(\"Verdana\", 12))\n",
    "        label.pack(pady=10, padx=10)\n",
    "\n",
    "        button1 = tk.Button(self, text=\"Back to Home\", command=lambda: controller.show_frame(StartPage), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        button1.pack()\n",
    "\n",
    "        def gif_stream():\n",
    "            global cnt\n",
    "            global gif_frames\n",
    "            if (cnt == len(gif_frames)):\n",
    "                return\n",
    "            img = gif_frames[cnt]\n",
    "            cnt += 1\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            gif_box.imgtk = imgtk\n",
    "            gif_box.configure(image=imgtk)\n",
    "            gif_box.after(50, gif_stream)\n",
    "\n",
    "        def hear_voice(inputtxt):\n",
    "            store = sr.Recognizer()\n",
    "            with sr.Microphone() as s:\n",
    "                audio_input = store.record(s, duration=10)\n",
    "                try:\n",
    "                    text_output = store.recognize_google(audio_input)\n",
    "                    inputtxt.insert(END, text_output)\n",
    "                    # Automatically convert to sign language after voice detection\n",
    "                    Take_input(inputtxt)\n",
    "                except:\n",
    "                    print(\"Error Hearing Voice\")\n",
    "                    inputtxt.insert(END, '')\n",
    "\n",
    "        def Take_input(inputtxt):\n",
    "            INPUT = inputtxt.get(\"1.0\", \"end-1c\")\n",
    "            print(INPUT)\n",
    "            global gif_frames\n",
    "            gif_frames = func(INPUT)\n",
    "            global cnt\n",
    "            cnt = 0\n",
    "            gif_stream()\n",
    "            gif_box.place(x=400, y=160)\n",
    "\n",
    "        l = tk.Label(self, text=\"Enter Text or Voice:\")\n",
    "        l1 = tk.Label(self, text=\"OR\")\n",
    "        inputtxt = tk.Text(self, height=4, width=25)\n",
    "        voice_button = tk.Button(self, height=2, width=20, text=\"Record Voice\", command=lambda: hear_voice(inputtxt), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        voice_button.place(x=50, y=180)\n",
    "        Display = tk.Button(self, height=2, width=20, text=\"Convert\", command=lambda: Take_input(inputtxt), bg='#189AB4', fg='black', font=(\"Verdana\", 10))\n",
    "        Display.place(x=50, y=250)\n",
    "        l.place(x=50, y=160)\n",
    "        l1.place(x=115, y=230)\n",
    "        inputtxt.place(x=50, y=250)\n",
    "        Display.pack()\n",
    "\n",
    "\n",
    "app = Tk_Manage()\n",
    "app.geometry(\"900x500\")\n",
    "app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3252c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387043a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
